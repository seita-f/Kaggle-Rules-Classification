{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13272190,"sourceType":"datasetVersion","datasetId":8410972},{"sourceId":13301573,"sourceType":"datasetVersion","datasetId":8431113},{"sourceId":166218,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":141432,"modelId":164048},{"sourceId":166245,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":141458,"modelId":164048},{"sourceId":487276,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":388639,"modelId":407569}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport re\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nSEED = 42\nbatch_size = 32","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:09:43.462630Z","iopub.execute_input":"2025-10-12T14:09:43.462891Z","iopub.status.idle":"2025-10-12T14:10:26.465082Z","shell.execute_reply.started":"2025-10-12T14:09:43.462872Z","shell.execute_reply":"2025-10-12T14:10:26.464217Z"}},"outputs":[{"name":"stderr","text":"2025-10-12 14:10:10.411217: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760278210.813514      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760278210.949746      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\")\n\nprint(\"train size: \", df_train.shape)\nprint(\"test size: \", df_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:15.697903Z","iopub.execute_input":"2025-10-12T14:12:15.698218Z","iopub.status.idle":"2025-10-12T14:12:15.738006Z","shell.execute_reply.started":"2025-10-12T14:12:15.698195Z","shell.execute_reply":"2025-10-12T14:12:15.737365Z"}},"outputs":[{"name":"stdout","text":"train size:  (2029, 9)\ntest size:  (10, 8)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"df_train.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:09:38.293866Z","iopub.status.idle":"2025-10-12T14:09:38.294140Z","shell.execute_reply.started":"2025-10-12T14:09:38.294011Z","shell.execute_reply":"2025-10-12T14:09:38.294024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T13:36:14.170066Z","iopub.execute_input":"2025-10-12T13:36:14.170294Z","iopub.status.idle":"2025-10-12T13:36:14.180035Z","shell.execute_reply.started":"2025-10-12T13:36:14.170276Z","shell.execute_reply":"2025-10-12T13:36:14.179314Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   row_id                                               body  \\\n0    2029  NEW RAP GROUP 17. CHECK US OUT https://soundcl...   \n1    2030  Make your life comfortable. Get up to 15% Disc...   \n2    2031  Kickin' ass and selling underwear!\\nJust made ...   \n3    2032   watch  hooters  best  therein  http://clickan...   \n4    2033   bitches  for free  at this point  show all  h...   \n\n                                                rule        subreddit  \\\n0  No Advertising: Spam, referral links, unsolici...      hiphopheads   \n1  No legal advice: Do not offer or request legal...        AskReddit   \n2  No Advertising: Spam, referral links, unsolici...         gonewild   \n3  No Advertising: Spam, referral links, unsolici...  personalfinance   \n4  No Advertising: Spam, referral links, unsolici...   Showerthoughts   \n\n                                  positive_example_1  \\\n0  Hey, guys, just wanted to drop in and invite y...   \n1  Get a lawyer and get the security camera foota...   \n2  Good story my friend. Check out my blog at  ht...   \n3  Earn 50,000 bonus points with Chase Sapphire P...   \n4  code free tyrande --->>> [Imgur](http://i.imgu...   \n\n                                  positive_example_2  \\\n0  Cum Swallowing Hottie Katrina Kaif Cartoon Xvi...   \n1  That isn't drastic. You tried reaching out to ...   \n2  If you know what exactly you need then you don...   \n3  Cool, front page! I made this print along with...   \n4  My trade link\\nhttps://steamcommunity.com/trad...   \n\n                                  negative_example_1  \\\n0  SD Stream Eng - [Chelsea TV USA](http://soccer...   \n1  So what are you going to do with the insurance...   \n2  CENTIPEDES\\n\\nSOME BASED PATRIOTS HAVE CREATED...   \n3  [Full HD Movie Online Free](http://www.flickma...   \n4  **HD** [ mio Stadium 102 HD](http://www.genti....   \n\n                                  negative_example_2  \n0  HD Streams: |[ENG HD Stoke vs Manchester Unite...  \n1  It's just for Austria & Germany. If you still ...  \n2  [So great! Thanks for sharing.](http://www.che...  \n3  * Karambit Black Pearl\\n* 0.02137822 Float (un...  \n4  Infographics is an incredible method for showi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>body</th>\n      <th>rule</th>\n      <th>subreddit</th>\n      <th>positive_example_1</th>\n      <th>positive_example_2</th>\n      <th>negative_example_1</th>\n      <th>negative_example_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2029</td>\n      <td>NEW RAP GROUP 17. CHECK US OUT https://soundcl...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>hiphopheads</td>\n      <td>Hey, guys, just wanted to drop in and invite y...</td>\n      <td>Cum Swallowing Hottie Katrina Kaif Cartoon Xvi...</td>\n      <td>SD Stream Eng - [Chelsea TV USA](http://soccer...</td>\n      <td>HD Streams: |[ENG HD Stoke vs Manchester Unite...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2030</td>\n      <td>Make your life comfortable. Get up to 15% Disc...</td>\n      <td>No legal advice: Do not offer or request legal...</td>\n      <td>AskReddit</td>\n      <td>Get a lawyer and get the security camera foota...</td>\n      <td>That isn't drastic. You tried reaching out to ...</td>\n      <td>So what are you going to do with the insurance...</td>\n      <td>It's just for Austria &amp; Germany. If you still ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2031</td>\n      <td>Kickin' ass and selling underwear!\\nJust made ...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>gonewild</td>\n      <td>Good story my friend. Check out my blog at  ht...</td>\n      <td>If you know what exactly you need then you don...</td>\n      <td>CENTIPEDES\\n\\nSOME BASED PATRIOTS HAVE CREATED...</td>\n      <td>[So great! Thanks for sharing.](http://www.che...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2032</td>\n      <td>watch  hooters  best  therein  http://clickan...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>personalfinance</td>\n      <td>Earn 50,000 bonus points with Chase Sapphire P...</td>\n      <td>Cool, front page! I made this print along with...</td>\n      <td>[Full HD Movie Online Free](http://www.flickma...</td>\n      <td>* Karambit Black Pearl\\n* 0.02137822 Float (un...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2033</td>\n      <td>bitches  for free  at this point  show all  h...</td>\n      <td>No Advertising: Spam, referral links, unsolici...</td>\n      <td>Showerthoughts</td>\n      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n      <td>My trade link\\nhttps://steamcommunity.com/trad...</td>\n      <td>**HD** [ mio Stadium 102 HD](http://www.genti....</td>\n      <td>Infographics is an incredible method for showi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"print('NA in train data:', df_train.isna().values.any())\nprint('NA in test data:', df_test.isna().values.any())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[\"rule_violation\"].hist(bins=2)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:11:53.791093Z","iopub.execute_input":"2025-10-12T14:11:53.791368Z","iopub.status.idle":"2025-10-12T14:11:53.795234Z","shell.execute_reply.started":"2025-10-12T14:11:53.791344Z","shell.execute_reply":"2025-10-12T14:11:53.794725Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def add_rule_and_subreddit(df):\n\n    new_df = pd.DataFrame()\n    new_df[\"data\"] = \"Rule: \" + df[\"rule\"] + \\\n              \" Subreddit: \" + df[\"subreddit\"] + \\\n              \" Comment: \" + df['body']\n    new_df[\"label\"] = df[\"rule_violation\"]\n\n    return new_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:21.447560Z","iopub.execute_input":"2025-10-12T14:12:21.447827Z","iopub.status.idle":"2025-10-12T14:12:21.451651Z","shell.execute_reply.started":"2025-10-12T14:12:21.447807Z","shell.execute_reply":"2025-10-12T14:12:21.451075Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# X = add_rule_and_subreddit(df_train)\n# print(X.loc[0,])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\n(Gray Rules): Adding Test data\n\"\"\"\ndf_sample = df_test.sample(frac=0.30, random_state=SEED).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:23.923673Z","iopub.execute_input":"2025-10-12T14:12:23.923937Z","iopub.status.idle":"2025-10-12T14:12:23.928600Z","shell.execute_reply.started":"2025-10-12T14:12:23.923918Z","shell.execute_reply":"2025-10-12T14:12:23.927993Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"\"\"\"\nData Augmentation using examples in train\n\"\"\"\n\n# positives\npos = df_train[[\"positive_example_1\", \"rule\", \"subreddit\"]].rename(\n    columns={\"positive_example_1\": \"body\"}\n)\npos[\"rule_violation\"] = 1\n\npos_2 = df_train[[\"positive_example_2\", \"rule\", \"subreddit\"]].rename(\n    columns={\"positive_example_2\": \"body\"}\n)\npos_2[\"rule_violation\"] = 1\n\n# negatives\nneg = df_train[[\"negative_example_1\", \"rule\", \"subreddit\"]].rename(\n    columns={\"negative_example_1\": \"body\"}\n)\nneg[\"rule_violation\"] = 0\n\nneg_2 = df_train[[\"negative_example_2\", \"rule\", \"subreddit\"]].rename(\n    columns={\"negative_example_2\": \"body\"}\n)\nneg_2[\"rule_violation\"] = 0\n\n# combine\ndf_add = pd.concat([pos, pos_2, neg, neg_2], ignore_index=True)\n\n# optional: drop missing texts, ensure int dtype\ndf_add = df_add.dropna(subset=[\"body\"]).reset_index(drop=True)\ndf_add[\"rule_violation\"] = df_add[\"rule_violation\"].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:25.286992Z","iopub.execute_input":"2025-10-12T14:12:25.287251Z","iopub.status.idle":"2025-10-12T14:12:25.302610Z","shell.execute_reply.started":"2025-10-12T14:12:25.287230Z","shell.execute_reply":"2025-10-12T14:12:25.301985Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"df_train = pd.concat([df_train, df_add], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:28.449742Z","iopub.execute_input":"2025-10-12T14:12:28.450265Z","iopub.status.idle":"2025-10-12T14:12:28.455881Z","shell.execute_reply.started":"2025-10-12T14:12:28.450241Z","shell.execute_reply":"2025-10-12T14:12:28.455120Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:30.393715Z","iopub.execute_input":"2025-10-12T14:12:30.394409Z","iopub.status.idle":"2025-10-12T14:12:30.398663Z","shell.execute_reply.started":"2025-10-12T14:12:30.394384Z","shell.execute_reply":"2025-10-12T14:12:30.397968Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(10145, 9)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"\"\"\"\nData Augmentation using examples in test\n\"\"\"\n\n# positives\npos = df_sample[[\"positive_example_1\", \"rule\", \"subreddit\"]].rename(\n    columns={\"positive_example_1\": \"body\"}\n)\npos[\"rule_violation\"] = 1\n\npos_2 = df_sample[[\"positive_example_2\", \"rule\", \"subreddit\"]].rename(\n    columns={\"positive_example_2\": \"body\"}\n)\npos_2[\"rule_violation\"] = 1\n\n# negatives\nneg = df_sample[[\"negative_example_1\", \"rule\", \"subreddit\"]].rename(\n    columns={\"negative_example_1\": \"body\"}\n)\nneg[\"rule_violation\"] = 0\n\nneg_2 = df_sample[[\"negative_example_2\", \"rule\", \"subreddit\"]].rename(\n    columns={\"negative_example_2\": \"body\"}\n)\nneg_2[\"rule_violation\"] = 0\n\n# combine\ndf_add = pd.concat([pos, pos_2, neg, neg_2], ignore_index=True)\n\n# optional: drop missing texts, ensure int dtype\ndf_add = df_add.dropna(subset=[\"body\"]).reset_index(drop=True)\ndf_add[\"rule_violation\"] = df_add[\"rule_violation\"].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:33.138013Z","iopub.execute_input":"2025-10-12T14:12:33.138269Z","iopub.status.idle":"2025-10-12T14:12:33.151240Z","shell.execute_reply.started":"2025-10-12T14:12:33.138250Z","shell.execute_reply":"2025-10-12T14:12:33.150653Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"df_train_aug = pd.concat([df_train, df_add], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:35.827570Z","iopub.execute_input":"2025-10-12T14:12:35.828147Z","iopub.status.idle":"2025-10-12T14:12:35.833065Z","shell.execute_reply.started":"2025-10-12T14:12:35.828125Z","shell.execute_reply":"2025-10-12T14:12:35.832502Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df_train_aug = add_rule_and_subreddit(df_train_aug)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:38.035796Z","iopub.execute_input":"2025-10-12T14:12:38.036037Z","iopub.status.idle":"2025-10-12T14:12:38.047045Z","shell.execute_reply.started":"2025-10-12T14:12:38.036020Z","shell.execute_reply":"2025-10-12T14:12:38.046432Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"print(df_train_aug[\"data\"].loc[9000,])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:39.851339Z","iopub.execute_input":"2025-10-12T14:12:39.851829Z","iopub.status.idle":"2025-10-12T14:12:39.856151Z","shell.execute_reply.started":"2025-10-12T14:12:39.851806Z","shell.execute_reply":"2025-10-12T14:12:39.855495Z"}},"outputs":[{"name":"stdout","text":"Rule: No legal advice: Do not offer or request legal advice. Subreddit: conspiracy Comment: Can you beat and rape her? Then get her pregnant and blame her afterwards? I mean it was her fault she was asking for it by being in the same room as me.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCapital letters count\n\"\"\"\n# def find_capitals(text):\n#     matches = re.findall(r\"[A-Z!]\", text)\n#     return len(matches)/len(text)\n    \n# df_train_aug[\"capital_ratio\"] = df_train_aug[\"data\"].apply(find_capitals)\n# sns.histplot(data=df_train_aug, x='capital_ratio', hue='label')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T13:36:45.144261Z","iopub.execute_input":"2025-10-12T13:36:45.144956Z","iopub.status.idle":"2025-10-12T13:36:46.756126Z","shell.execute_reply.started":"2025-10-12T13:36:45.144932Z","shell.execute_reply":"2025-10-12T13:36:46.755474Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  data_subset = grouped_data.get_group(pd_key)\n/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n  data_subset = grouped_data.get_group(pd_key)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<Axes: xlabel='capital_ratio', ylabel='Count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"\"\"\"\nURLs count\n\"\"\"\n# def find_url(text):\n#     # Finds a full URL starting with http or https    \n#     matches = re.findall(r\"(?:http|https)://[^\\s]+\", text)\n\n#     if matches:\n#         return True\n#     else:\n#         return False\n\n# df_train_aug['url'] = df_train_aug['data'].apply(find_url)\n\n# # group label and url \n# plot_data = df_train_aug.groupby(['label', 'url']).size().reset_index(name='Count')\n\n\n# # visuzalize\n# sns.set_style(\"whitegrid\")\n# plt.figure(figsize=(7, 5))\n# palette_dict = {True: 'teal', False: 'darkorange'}\n\n# bar_plot = sns.barplot(\n#     data=plot_data,\n#     x='label',\n#     y='Count',\n#     hue='url', \n#     palette=palette_dict\n# )\n\n# plt.title('Count of URLs (True/False) per Label Category', fontsize=14)\n# plt.xlabel('Label Category', fontsize=12)\n# plt.ylabel('Count', fontsize=12)\n# plt.legend(title='URL Present', loc='upper right')\n\n# for container in bar_plot.containers:\n#     bar_plot.bar_label(container)\n\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T12:01:33.566409Z","iopub.execute_input":"2025-10-12T12:01:33.566646Z","iopub.status.idle":"2025-10-12T12:01:33.581674Z","shell.execute_reply.started":"2025-10-12T12:01:33.566625Z","shell.execute_reply":"2025-10-12T12:01:33.580873Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# print(df_train_aug[\"label\"].loc[3,])\n# print(df_train_aug[\"data\"].loc[3,]) # --> http://sh.ors.it/PALI2 (Not really helpful)\n\n# print(df_train_aug[\"label\"].loc[4,])\n# print(df_train_aug[\"data\"].loc[4,]) # --> www.paypal.com (\"paypal\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T12:01:33.582519Z","iopub.execute_input":"2025-10-12T12:01:33.582909Z","iopub.status.idle":"2025-10-12T12:01:33.597993Z","shell.execute_reply.started":"2025-10-12T12:01:33.582885Z","shell.execute_reply":"2025-10-12T12:01:33.597440Z"}},"outputs":[{"name":"stdout","text":"1\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed. Subreddit: sex Comment: she will come your home open her legs with  and  you http://sh.ors.it/PALI2\n1\nRule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed. Subreddit: hearthstone Comment: code free tyrande --->>> [Imgur](http://i.imgur.com/KlvssCl.png)\n\nfor you and your friend 2 codes for 4 dollars https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=UN4E27AG7BWKS\n\n2$... buy one directly from here: https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=VP3S5HQRE7T7E\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\"\"\"\nWord Count\n\"\"\"\n# df_train_aug['word_count'] = df_train_aug['data'].map(lambda calc: len(calc))\n# sns.histplot(data=df_train_aug, x='word_count', hue='label')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T13:36:52.157583Z","iopub.execute_input":"2025-10-12T13:36:52.158188Z","iopub.status.idle":"2025-10-12T13:36:52.167239Z","shell.execute_reply.started":"2025-10-12T13:36:52.158166Z","shell.execute_reply":"2025-10-12T13:36:52.166363Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Text cleaning / Deature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Prompt Engineering (URL to Keyword)","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# LLM_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/1.5b-instruct/1\"\n\n# model = AutoModelForCausalLM.from_pretrained(\n#     LLM_MODEL_PATH,\n#     torch_dtype=\"auto\",\n#     device_map=\"auto\"\n# )\n# tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T12:22:09.115226Z","iopub.execute_input":"2025-10-12T12:22:09.115823Z","iopub.status.idle":"2025-10-12T12:22:40.527025Z","shell.execute_reply.started":"2025-10-12T12:22:09.115796Z","shell.execute_reply":"2025-10-12T12:22:40.526385Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# def build_prompt(url):\n\n#     prompt = (\n#         f\"Please list 3 to 5 keywords that are likely related to the content of this URL: {url}. \"\n#         f\"Answer the keywords only, separated by commas.\"\n#     )\n    \n#     messages = [\n#         {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n#         {\"role\": \"user\", \"content\": prompt}\n#     ]\n    \n#     # Qwen-Chat\n#     text = tokenizer.apply_chat_template(\n#         messages,\n#         tokenize=False,\n#         add_generation_prompt=True\n#     )\n\n#     model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n    \n#     generated_ids = model.generate(\n#         **model_inputs,\n#         max_new_tokens=100,\n#         do_sample=True,\n#         temperature=0.2,\n#         top_p=0.9\n#     )\n    \n#     generated_ids = [\n#         output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n#     ]\n    \n#     response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n#     keywords = re.findall(r\"[A-Za-z0-9\\-]+\", response)\n#     return [kw.lower() for kw in keywords if kw.lower() not in [\"keywords\"]]\n    \n\n# def replace_url_to_keywords(text):\n#     # Retrieve urls（http/https/www.）\n#     urls = re.findall(r'https?://\\S+|www\\.\\S+', text)\n#     # print(urls)\n#     for url in urls:\n#         try:\n#             keywords = build_prompt(url)\n#             keyword_str = \", \".join(keywords)\n#             replacement = f\"<URL: {keyword_str}>\"\n#             text = text.replace(url, replacement)\n        \n#         except Exception as e:\n#             print(f\"Error processing {url}: {e}\")\n#             text = text.replace(url, \"<URL: unknown>\")\n    \n#     return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T12:22:40.555811Z","iopub.execute_input":"2025-10-12T12:22:40.556233Z","iopub.status.idle":"2025-10-12T12:22:40.571725Z","shell.execute_reply.started":"2025-10-12T12:22:40.556217Z","shell.execute_reply":"2025-10-12T12:22:40.571049Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# # Test\n# url = \"https://onlyfans.com/user123\"\n# print(build_prompt(url))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T12:23:18.849511Z","iopub.execute_input":"2025-10-12T12:23:18.849804Z","iopub.status.idle":"2025-10-12T12:23:22.372714Z","shell.execute_reply.started":"2025-10-12T12:23:18.849781Z","shell.execute_reply":"2025-10-12T12:23:22.372120Z"}},"outputs":[{"name":"stdout","text":"['onlyfans', 'user123', 'content', 'entertainment', 'social', 'media']\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# df_train_aug[\"data\"] = df_train_aug[\"data\"].apply(replace_url_to_keywords)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"y = df_train_aug[\"label\"]\nX = df_train_aug[\"data\"]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:46.815550Z","iopub.execute_input":"2025-10-12T14:12:46.816237Z","iopub.status.idle":"2025-10-12T14:12:46.823862Z","shell.execute_reply.started":"2025-10-12T14:12:46.816213Z","shell.execute_reply":"2025-10-12T14:12:46.823228Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Token and Encode Function\ndef tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n    # Initialize empty lists to store tokenized inputs and attention masks\n    input_ids = []\n    attention_masks = []\n\n    # Iterate through each comment in the 'comments' list\n    for comment in comments:\n\n        # Tokenize and encode the comment using the BERT tokenizer\n        encoded_dict = tokenizer.encode_plus(\n            comment,\n\n            # Add special tokens like [CLS] and [SEP]\n            add_special_tokens=True,\n\n            truncation=True,\n            \n            # Truncate or pad the comment to 'max_length'\n            max_length=max_length,\n\n            # Pad the comment to 'max_length' with zeros if needed\n            padding='max_length',\n\n            # Return attention mask to mask padded tokens\n            return_attention_mask=True,\n\n            # Return PyTorch tensors\n            return_tensors='pt'\n        )\n\n        # Append the tokenized input and attention mask to their respective lists\n        input_ids.append(encoded_dict['input_ids'])\n        attention_masks.append(encoded_dict['attention_mask'])\n\n    # Concatenate the tokenized inputs and attention masks into tensors\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n\n    # Convert the labels to a PyTorch tensor with the data type float32\n    labels = torch.tensor(labels, dtype=torch.float32)\n\n    # Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n    return input_ids, attention_masks, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:48.364299Z","iopub.execute_input":"2025-10-12T14:12:48.365043Z","iopub.status.idle":"2025-10-12T14:12:48.370541Z","shell.execute_reply.started":"2025-10-12T14:12:48.365019Z","shell.execute_reply":"2025-10-12T14:12:48.369800Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## Bert-base","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoTokenizer, RobertaForSequenceClassification\n\n# tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n# model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.save_pretrained(\"my-roberta-base-cls\")\n# tokenizer.save_pretrained(\"my-roberta-base-cls\")\n# batch_size = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MODEL_DIR = \"/kaggle/input/my-base-bert/my-bert-cls\"\n\n# tokenizer = BertTokenizer.from_pretrained(\n#     MODEL_DIR,\n#     do_lower_case=True,\n#     local_files_only=True\n# )\n\n# config = BertConfig.from_pretrained(\n#     MODEL_DIR,\n#     local_files_only=True\n# )\n\n# model = BertForSequenceClassification.from_pretrained(\n#     MODEL_DIR,\n#     config=config,\n#     local_files_only=True\n# )\n# batch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T13:58:56.411435Z","iopub.execute_input":"2025-10-12T13:58:56.411839Z","iopub.status.idle":"2025-10-12T13:58:56.415392Z","shell.execute_reply.started":"2025-10-12T13:58:56.411809Z","shell.execute_reply":"2025-10-12T13:58:56.414694Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Deberta-v3-base","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n    DataCollatorWithPadding\n)\n\nMODEL_DIR = \"/kaggle/input/deberta-v3-base/transformers/default/1/deberta-v3-base\"\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    MODEL_DIR,\n    use_fast=True,\n    local_files_only=True\n)  \n\n# Config\nconfig = AutoConfig.from_pretrained(\n    MODEL_DIR,\n    num_labels=1,\n    problem_type=\"single_label_classification\",\n    local_files_only=True\n)\n\n# Model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_DIR,\n    config=config,\n    local_files_only=True\n)\n\n# For dynamic padding in your DataLoader/Trainer:\n# data_collator = DataCollatorWithPadding(\n#     tokenizer=tokenizer,\n#     pad_to_multiple_of=8  # helpful for fp16, optional\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:12:56.765900Z","iopub.execute_input":"2025-10-12T14:12:56.766371Z","iopub.status.idle":"2025-10-12T14:12:59.770509Z","shell.execute_reply.started":"2025-10-12T14:12:56.766347Z","shell.execute_reply":"2025-10-12T14:12:59.769918Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/deberta-v3-base/transformers/default/1/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Qwen3-0.6B","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n\n# QWEN_MODEL_DIR = \"/kaggle/input/qwen2.5/transformers/0.5b/1\"\n\n# # load the tokenizer and the model\n# tokenizer = AutoTokenizer.from_pretrained(\n#     QWEN_MODEL_DIR, \n#     padding=True,\n#     truncation=True,\n#     trust_remote_code=True)\n    \n# model = AutoModelForSequenceClassification.from_pretrained(\n#     QWEN_MODEL_DIR,\n#     num_labels=1,\n#     trust_remote_code=True\n# )\n\n\n# batch_size = 8","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"# # prepare the model input\n# prompt = \"Give me a short introduction to large language model.\"\n# messages = [\n#     {\"role\": \"user\", \"content\": prompt}\n# ]\n# text = tokenizer.apply_chat_template(\n#     messages,\n#     tokenize=False,\n#     add_generation_prompt=True,\n#     enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n# )\n# model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# # conduct text completion\n# generated_ids = model.generate(\n#     **model_inputs,\n#     max_new_tokens=32768\n# )\n# output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# # parsing thinking content\n# try:\n#     # rindex finding 151668 (</think>)\n#     index = len(output_ids) - output_ids[::-1].index(151668)\n# except ValueError:\n#     index = 0\n\n# thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n# content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\n# print(\"thinking content:\", thinking_content)\n# print(\"content:\", content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:06.257564Z","iopub.execute_input":"2025-10-12T14:13:06.258250Z","iopub.status.idle":"2025-10-12T14:13:06.672628Z","shell.execute_reply.started":"2025-10-12T14:13:06.258224Z","shell.execute_reply":"2025-10-12T14:13:06.671847Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Tokenize and Encode the comments and labels for the training set\ninput_ids, attention_masks, labels = tokenize_and_encode(\n    tokenizer,\n    X_train,\n    y_train.values\n)\n\n# Tokenize and Encode the comments and labels for the validation set\nval_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n    tokenizer,\n    X_val,\n    y_val.values\n)\n\nprint('Training Comments :',X_train.shape)\nprint('Input Ids         :',input_ids.shape)\nprint('Attention Mask    :',attention_masks.shape)\nprint('Labels            :',labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:11.269919Z","iopub.execute_input":"2025-10-12T14:13:11.270189Z","iopub.status.idle":"2025-10-12T14:13:14.786745Z","shell.execute_reply.started":"2025-10-12T14:13:11.270168Z","shell.execute_reply":"2025-10-12T14:13:14.786092Z"}},"outputs":[{"name":"stdout","text":"Training Comments : (6094,)\nInput Ids         : torch.Size([6094, 128])\nAttention Mask    : torch.Size([6094, 128])\nLabels            : torch.Size([6094])\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Creating DataLoader for the balanced dataset\ntrain_dataset = TensorDataset(input_ids, attention_masks, labels)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# validation set \nval_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:14.787677Z","iopub.execute_input":"2025-10-12T14:13:14.787939Z","iopub.status.idle":"2025-10-12T14:13:14.792187Z","shell.execute_reply.started":"2025-10-12T14:13:14.787920Z","shell.execute_reply":"2025-10-12T14:13:14.791490Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def plot_traing(train_losses, val_losses, train_f1s, val_f1s):\n\n    plt.figure(figsize=(12, 5))\n\n    # Training Loss & Validation Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss over Epochs')\n    plt.legend()\n\n    # Training Accuracy & Validation F1 Score\n    plt.subplot(1, 2, 2)\n    plt.plot(train_f1s, label='Train Accuracy')\n    plt.plot(val_f1s, label='Val F1 Score')\n    plt.xlabel('Epoch')\n    plt.ylabel('Score')\n    plt.title('Accuracy & F1 Score over Epochs')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:19.324046Z","iopub.execute_input":"2025-10-12T14:13:19.324756Z","iopub.status.idle":"2025-10-12T14:13:19.329636Z","shell.execute_reply.started":"2025-10-12T14:13:19.324729Z","shell.execute_reply":"2025-10-12T14:13:19.328935Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import copy\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import roc_auc_score\n\ndef train_model(model, train_loader, val_loader, device, num_epochs, patience=5):\n    loss_fn = nn.BCELoss()  # binary cross entropy\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n    # loss_fn = nn.BCEWithLogitsLoss()  \n    # optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n    \n    best_f1 = -1.0\n    # best_auc = -1.0\n    epochs_no_improve = 0\n    best_state = None\n\n    train_losses, val_losses, train_f1s, val_f1s = [], [], [], []\n    # train_losses, val_losses, train_aucs, val_aucs = [], [], [], []\n    \n    for epoch in range(num_epochs):\n\n        model.train()\n        total_loss = 0.0\n        all_train_preds, all_train_labels = [], []\n        # train\n        for batch in train_loader:\n            \n            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n            labels = labels.float()\n\n            # prediction (number of batches)\n            output = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = output.logits.squeeze(-1)\n            probs = torch.sigmoid(logits)  # convert logits to probabilities first\n            # print(logits) # DEBUG\n            \n            # forward pass\n            # loss = loss_fn(logits, labels)\n            loss = loss_fn(probs, labels)\n            # print(loss) # DEBUG\n            \n            total_loss += loss.item()\n\n            # backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            \n            # update weights\n            optimizer.step()\n\n            preds = (probs > 0.5).long()\n            all_train_preds.extend(preds.cpu().tolist())\n            all_train_labels.extend(labels.cpu().tolist())\n            \n        train_loss = total_loss / len(train_loader)\n        train_f1 = f1_score(all_train_labels, all_train_preds)\n\n        train_losses.append(train_loss)\n        train_f1s.append(train_f1)\n        \n        # Validate\n        model.eval()\n        val_loss = 0.0\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                \n                input_ids, attention_mask, labels = [t.to(device) for t in batch]\n                labels = labels.float()\n                output = model(input_ids=input_ids, attention_mask=attention_mask)\n                logits = output.logits.squeeze(-1)\n                probs = torch.sigmoid(logits)\n                val_loss += loss_fn(probs, labels.float()).item()\n                \n                preds = (probs > 0.5).long()\n                all_preds.extend(preds.cpu().tolist())\n                all_labels.extend(labels.cpu().tolist())\n                \n        val_f1 = f1_score(all_labels, all_preds)\n        val_f1s.append(val_f1)\n        \n        val_losses.append(val_loss)\n        val_loss /= len(val_loader)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_f1:.4f} - \"\n              f\"Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            epochs_no_improve = 0\n            best_state = copy.deepcopy(model.state_dict())\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                print(f\"Early stopping (no val F1 improvement for {patience} epochs). Best Val F1: {best_f1:.4f}\")\n                break\n\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    # visualize training\n    plot_traing(train_losses, val_losses, train_f1s, val_f1s)\n    # plot_traing(train_losses, val_losses, train_aucs, val_aucs)\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:21.829853Z","iopub.execute_input":"2025-10-12T14:13:21.830590Z","iopub.status.idle":"2025-10-12T14:13:21.842235Z","shell.execute_reply.started":"2025-10-12T14:13:21.830564Z","shell.execute_reply":"2025-10-12T14:13:21.841620Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Call the function to train the model\nmodel = train_model(model, train_loader, val_loader, device, num_epochs=50, patience=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:13:29.485406Z","iopub.execute_input":"2025-10-12T14:13:29.485692Z","iopub.status.idle":"2025-10-12T14:19:04.880540Z","shell.execute_reply.started":"2025-10-12T14:13:29.485670Z","shell.execute_reply":"2025-10-12T14:19:04.879411Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50 - Train Loss: 0.6928, Train Acc: 0.5367 - Val Loss: 0.7045, Val F1: 0.0000\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1067028396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call the function to train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/448282738.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# prediction (number of batches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert logits to probabilities first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         outputs = self.deberta(\n\u001b[0m\u001b[1;32m   1090\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    794\u001b[0m         )\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 )\n\u001b[1;32m    668\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 output_states, attn_weights = layer_module(\n\u001b[0m\u001b[1;32m    670\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         )\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":42},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def add_rule_and_subreddit(df):\n\n    new_df = pd.DataFrame()\n    \n    new_df[\"data\"] = \"Rule: \" + df[\"rule\"] + \\\n              \" Subreddit: \" + df[\"subreddit\"] + \\\n              \" Comment: \" + df['body']\n    \n    new_df[\"row_id\"] = df[\"row_id\"]\n\n    return new_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_temp = add_rule_and_subreddit(df_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_test(tokenizer, comments, max_length=128):\n    input_ids, attention_masks = [], []\n    for comment in comments:\n        enc = tokenizer.encode_plus(\n            comment,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=max_length,\n            padding=\"max_length\",\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n        input_ids.append(enc[\"input_ids\"])\n        attention_masks.append(enc[\"attention_mask\"])\n    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n\ntest_input_ids, test_attention_masks = tokenize_test(tokenizer, df_temp[\"data\"], max_length=128)\ntest_dataset = TensorDataset(test_input_ids, test_attention_masks)\ntest_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict(model, loader, device):\n    model.eval()\n    all_preds = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for batch in loader:\n            input_ids, attention_mask = [t.to(device) for t in batch]\n            \n            output = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            logits = output.logits.squeeze(-1)\n            probs = torch.sigmoid(logits)\n            all_probs.extend(probs.cpu().tolist())\n            \n    return all_probs\n\nres = predict(model, test_loader, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"res","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame(df_temp[\"row_id\"])\nsubmission[\"rule_violation\"] = res","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}